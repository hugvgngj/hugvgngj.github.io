<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>folder</title>
    <url>/2019/12/04/folder/</url>
    <content><![CDATA[<p><img src="/2019/12/04/folder/why.jpg" class title="examplename}&lt;&#x2F;p&gt;"></p>]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>image</tag>
      </tags>
  </entry>
  <entry>
    <title>my first successful blog</title>
    <url>/2019/11/01/my-first-successful-blog/</url>
    <content><![CDATA[<p>测试tags和categories是否正常</p>
]]></content>
      <categories>
        <category>test</category>
      </categories>
  </entry>
  <entry>
    <title>my first successful blog</title>
    <url>/2019/11/01/test/my-first-successful-blog/</url>
    <content><![CDATA[<p>测试tags和categories是否正常</p>
]]></content>
      <categories>
        <category>test</category>
      </categories>
  </entry>
  <entry>
    <title>welcome</title>
    <url>/2019/12/04/test/welcome%20to%20my%20blog/</url>
    <content><![CDATA[<p>nothing to say</p>
]]></content>
      <tags>
        <tag>copy</tag>
      </tags>
  </entry>
  <entry>
    <title>welcome</title>
    <url>/2019/12/04/test/welcome/</url>
    <content><![CDATA[<p>nothing to say</p>
]]></content>
      <tags>
        <tag>hello</tag>
      </tags>
  </entry>
  <entry>
    <title>withimage</title>
    <url>/2019/12/04/test/withimage/</url>
    <content><![CDATA[<p>这是第一个有图的博文<br>图在这里：<br><img src="/2019/12/04/test/withimage/a.jpg" alt="义工招募"><br>让我们看看效果怎么样</p>
]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>image</tag>
      </tags>
  </entry>
  <entry>
    <title>网络压缩/adversarial</title>
    <url>/2019/12/05/%E7%BD%91%E7%BB%9C%E5%8E%8B%E7%BC%A9/adversarial/</url>
    <content><![CDATA[<h3 id="论文名称"><a href="#论文名称" class="headerlink" title="论文名称"></a>论文名称</h3><p><a href="https://arxiv.org/pdf/1810.00208.pdf" target="_blank" rel="noopener">To Compress or Not to Compress: Understanding the Interactions between Adversarial Attacks and Neural Network Compression</a></p>
<h3 id="论文重述"><a href="#论文重述" class="headerlink" title="论文重述"></a>论文重述</h3><p>该论文主要是讨论对抗攻击在压缩模型上的可迁移性 (Transferability)，分为三种情形：</p>
<ul>
<li>compressed 产生对抗样本测试自身</li>
<li>baseline 产生对抗样本测试 compressed</li>
<li>compressed 产生对抗样本测试 baseline<br>比较的压缩方式为：剪枝 和 量化<br>比较的攻击方法为：IFGSM, IFGM, Deepfool</li>
</ul>
<h3 id="比较结果"><a href="#比较结果" class="headerlink" title="比较结果"></a>比较结果</h3><ul>
<li><p>剪枝方法</p>
<ol>
<li><p>对于 IFGM 和 IFGSM 方法，对抗样本的迁移性是受到剪枝过后密度减小造成影响的。具体表现在：</p>
<ul>
<li>当密度小的时候，用compressed生成的对抗样本去攻击baseline的效果不错，从小到大迁移性好</li>
<li>当密度小的时候，用baseline生成的对抗样本去攻击compressed效果不好，从大到小迁移性不好</li>
</ul>
</li>
<li><p>对于 Deepfool 方法，小的生成样本攻击自身，小的生成样本攻击大的，这两种情况在密度减小的时候迁移性都更好。</p>
</li>
<li><p>因为clipped的原因，对于有clipped的方法（IFGSM and IFGM），小的生成样本攻击自身，大的生成样本攻击小的，这两种情况在密度减小的时候迁移性都更不好。</p>
</li>
</ol>
</li>
<li><p>量化方法</p>
<ol>
<li><p>当量化精度高的时候，在量化与不量化之间的攻击效果不受影响</p>
</li>
<li><p>当小数位数减小的很厉害时类似fine-grained pruning（剪枝权重）的效果</p>
</li>
<li><p>整数位数很少的时候，小的产生样本攻击大的会变得异常困难，表明类别的语义信息保存在activations and weights中</p>
</li>
</ol>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong><em>（以下仅表示个人观点，欢迎讨论指正）</em></strong></p>
<p>就像看了一份实验报告一样，没有新方法，主要是比较结果。</p>
<p>个人感觉方法分的太细了，特别是攻击方法，感觉 ①没有从攻击原理的角度阐释可迁移性，②只是众多攻击模型中的典型三种，且IFGSM，IFGM和Deepfool的区别还挺大的，感觉又只像两类攻击方法。总之感觉脱离数学原理的比较都显得不那么全面。</p>
<p>亮点：</p>
<ul>
<li>use Mayo tool to generate pruned and quantised models</li>
<li>对于应用的讨论，作者最终的结论是公司用压缩模型发行并不会增加大模型的安全性</li>
</ul>
]]></content>
  </entry>
</search>
